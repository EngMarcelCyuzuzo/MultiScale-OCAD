{"cells":[{"cell_type":"code","source":["!git clone https://{EngMarcelCyuzuzo}:{passenger0123&}@github.com/{MultiScale-OCAD}/{MultiScale-OCAD}.git\n","%cd /content/{MultiScale-OCAD}\n","\n","!git config --global user.name \"{EngMarcelCyuzuzo}\"\n","!git config --global user.email \"{mcimc654@gmail.com}\"\n","!git config --global user.password \"{passenger0123&}\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaNr8qgWtQt8","executionInfo":{"status":"ok","timestamp":1755932387496,"user_tz":-480,"elapsed":570,"user":{"displayName":"mc mci","userId":"16017943219629278430"}},"outputId":"2a21538f-4ab6-4ae6-afa7-da78498ccf82"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: }@github.com/{MultiScale-OCAD}/{MultiScale-OCAD}.git: No such file or directory\n","Cloning into '{passenger0123'...\n","fatal: unable to access 'https://{EngMarcelCyuzuzo}:{passenger0123/': URL using bad/illegal format or missing URL\n","[Errno 2] No such file or directory: '/content/{MultiScale-OCAD}'\n","/content\n"]}]},{"cell_type":"code","source":["!git config --global user.name \"EngMarcelCyuzuzo\"\n","!git config --global user.email \"mcimc654@gmail.com\"\n","!git config --global user.password \"passenger0123&\""],"metadata":{"id":"0guG45QrUq0x","executionInfo":{"status":"ok","timestamp":1755930814742,"user_tz":-480,"elapsed":581,"user":{"displayName":"mc mci","userId":"16017943219629278430"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["token = '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'\n","username = 'EngMarcelCyuzuzo'\n","repo = 'MultiScale-OCAD'"],"metadata":{"id":"eFYyEYJ-VJdz","executionInfo":{"status":"ok","timestamp":1755930816357,"user_tz":-480,"elapsed":184,"user":{"displayName":"mc mci","userId":"16017943219629278430"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/EngMarcelCyuzuzo/MultiScale-OCAD.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UywQH4TnfLsz","executionInfo":{"status":"ok","timestamp":1755931275047,"user_tz":-480,"elapsed":406,"user":{"displayName":"mc mci","userId":"16017943219629278430"}},"outputId":"569e5d5e-cb29-4e4e-abf3-700a4dd212ad"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MultiScale-OCAD'...\n","fatal: could not read Username for 'https://github.com': No such device or address\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2LqECkbpmchM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import glob\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision import transforms, models\n","from sklearn.svm import OneClassSVM\n","from sklearn.model_selection import GridSearchCV\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Enhanced configuration\n","config = {\n","    'image_size': (1024, 1024),\n","    'batch_size': 16,\n","    'num_augmentations': 10,\n","    'feature_layers': ['layer2', 'layer3', 'layer4'],\n","    'ocsvm_params': {\n","        'kernel': ['rbf', 'sigmoid'],\n","        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n","        'nu': [0.01, 0.05, 0.1, 0.2]\n","    },\n","    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","}\n","\n","# Mount Google Drive (Colab specific)\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/"],"metadata":{"id":"uS1-PrUNR_sR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load dataset\n","bad_dir = sorted(glob.glob('/content/drive/MyDrive/anomaly_data/bad/*'))\n","good_dir = sorted(glob.glob('/content/drive/MyDrive/anomaly_data/good/*'))\n","\n","# Enhanced transforms with augmentation\n","train_transform = transforms.Compose([\n","    transforms.Resize(config['image_size']),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize(config['image_size']),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","class AugmentedDataset(Dataset):\n","    \"\"\"Dataset with augmented good samples\"\"\"\n","    def __init__(self, good_files, bad_files, transform=None, num_augmentations=5):\n","        self.good_files = good_files\n","        self.bad_files = bad_files\n","        self.transform = transform\n","        self.num_augmentations = num_augmentations\n","        self.all_files = good_files + bad_files\n","        self.labels = [0] * len(good_files) + [1] * len(bad_files)\n","\n","    def __len__(self):\n","        return len(self.good_files) * self.num_augmentations + len(self.bad_files)\n","\n","    def __getitem__(self, idx):\n","        if idx < len(self.good_files) * self.num_augmentations:\n","            # Augmented good sample\n","            file_idx = idx % len(self.good_files)\n","            img = Image.open(self.good_files[file_idx]).convert('RGB')\n","            label = 0\n","        else:\n","            # Bad sample (no augmentation)\n","            bad_idx = idx - len(self.good_files) * self.num_augmentations\n","            img = Image.open(self.bad_files[bad_idx]).convert('RGB')\n","            label = 1\n","\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label\n","\n","# Split data (80% train, 20% test)\n","from sklearn.model_selection import train_test_split\n","train_good, test_good = train_test_split(good_dir, test_size=0.2, random_state=42)\n","train_bad, test_bad = train_test_split(bad_dir, test_size=0.2, random_state=42)\n","\n","# Create datasets\n","train_dataset = AugmentedDataset(\n","    train_good, train_bad,\n","    transform=train_transform,\n","    num_augmentations=config['num_augmentations']\n",")\n","\n","test_dataset = AugmentedDataset(\n","    test_good, test_bad,\n","    transform=test_transform,\n","    num_augmentations=1  # No augmentation for test\n",")\n","\n","# Create dataloaders\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=config['batch_size'],\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=config['batch_size'],\n","    shuffle=False,\n","    num_workers=2\n",")\n","\n","# Enhanced feature extractor\n","class MultiLayerFeatureExtractor(nn.Module):\n","    def __init__(self, backbone='wide_resnet50_2'):\n","        super().__init__()\n","        self.backbone = getattr(models, backbone)(pretrained=True)\n","        self.feature_layers = config['feature_layers']\n","        self.features = {}\n","        self.hooks = []\n","\n","        # Register hooks\n","        for layer_name in self.feature_layers:\n","            layer = dict([*self.backbone.named_modules()])[layer_name]\n","            self.hooks.append(layer.register_forward_hook(self.get_features(layer_name)))\n","\n","        self.backbone.eval()\n","\n","    def get_features(self, layer_name):\n","        def hook(module, input, output):\n","            self.features[layer_name] = output.detach()\n","        return hook\n","\n","    def forward(self, x):\n","        self.features = {}\n","        _ = self.backbone(x)\n","        return [self.features[layer] for layer in self.feature_layers]\n","\n","    def release(self):\n","        for hook in self.hooks:\n","            hook.remove()\n","\n","# Initialize feature extractor\n","feature_extractor = MultiLayerFeatureExtractor().to(config['device'])\n","\n","def extract_features(loader):\n","    \"\"\"Extract multi-scale features from images\"\"\"\n","    features = {layer: [] for layer in config['feature_layers']}\n","    labels = []\n","\n","    with torch.no_grad():\n","        for images, targets in tqdm(loader):\n","            images = images.to(config['device'])\n","            targets = targets.cpu().numpy()\n","\n","            # Extract features\n","            layer_features = feature_extractor(images)\n","\n","            # Process each layer\n","            for i, layer in enumerate(config['feature_layers']):\n","                # Global average pooling\n","                pooled = nn.AdaptiveAvgPool2d((1, 1))(layer_features[i])\n","                flattened = pooled.view(pooled.size(0), -1).cpu().numpy()\n","                features[layer].append(flattened)\n","\n","            labels.append(targets)\n","\n","    # Concatenate results\n","    for layer in config['feature_layers']:\n","        features[layer] = np.concatenate(features[layer])\n","\n","    labels = np.concatenate(labels)\n","    return features, labels\n","\n","print(\"Extracting training features...\")\n","train_features, train_labels = extract_features(train_loader)\n","\n","print(\"Extracting test features...\")\n","test_features, test_labels = extract_features(test_loader)\n","\n","# Feature aggregation\n","def aggregate_features(feature_dict):\n","    \"\"\"Aggregate features from multiple layers\"\"\"\n","    aggregated = []\n","    for layer in config['feature_layers']:\n","        # Standardize features\n","        layer_features = feature_dict[layer]\n","        mean = np.mean(layer_features, axis=0)\n","        std = np.std(layer_features, axis=0) + 1e-8\n","        standardized = (layer_features - mean) / std\n","        aggregated.append(standardized)\n","\n","    # Concatenate all layer features\n","    return np.concatenate(aggregated, axis=1)\n","\n","train_features_agg = aggregate_features(train_features)\n","test_features_agg = aggregate_features(test_features)\n","\n","# Separate good and bad features\n","train_good_features = train_features_agg[train_labels == 0]\n","train_bad_features = train_features_agg[train_labels == 1]\n","\n","test_good_features = test_features_agg[test_labels == 0]\n","test_bad_features = test_features_agg[test_labels == 1]\n","\n","# Optimize OCSVM parameters\n","print(\"Optimizing OCSVM parameters...\")\n","ocsvm = OneClassSVM()\n","grid_search = GridSearchCV(\n","    ocsvm,\n","    config['ocsvm_params'],\n","    scoring='average_precision',\n","    cv=3,\n","    n_jobs=-1,\n","    verbose=1\n",")\n","\n","# Train only on good samples\n","grid_search.fit(train_good_features)\n","\n","# Get best model\n","best_ocsvm = grid_search.best_estimator_\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","print(f\"Best validation mAP: {grid_search.best_score_:.4f}\")\n","\n","# Train final model on all good samples\n","print(\"Training final model...\")\n","all_good_features = np.concatenate([train_good_features, test_good_features])\n","best_ocsvm.fit(all_good_features)\n","\n","# Evaluate on test set\n","def evaluate_model(model, good_features, bad_features, model_name):\n","    \"\"\"Evaluate model and plot results\"\"\"\n","    # Calculate scores\n","    good_scores = -model.decision_function(good_features)  # Higher = more anomalous\n","    bad_scores = -model.decision_function(bad_features)\n","\n","    # Combine scores and labels\n","    y_scores = np.concatenate([good_scores, bad_scores])\n","    y_true = np.concatenate([np.zeros(len(good_scores)), np.ones(len(bad_scores))])\n","\n","    # Calculate metrics\n","    from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n","    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n","    avg_precision = average_precision_score(y_true, y_scores)\n","    auroc = roc_auc_score(y_true, y_scores)\n","\n","    # Find optimal threshold\n","    f1_scores = (2 * precision * recall) / (precision + recall + 1e-8)\n","    best_idx = np.argmax(f1_scores)\n","    optimal_threshold = thresholds[best_idx]\n","\n","    # Apply optimal threshold\n","    y_pred = (y_scores >= optimal_threshold).astype(int)\n","    from sklearn.metrics import classification_report\n","    report = classification_report(y_true, y_pred, target_names=['Good', 'Defective'])\n","\n","    # Plot results\n","    plt.figure(figsize=(15, 5))\n","\n","    # Precision-Recall curve\n","    plt.subplot(121)\n","    plt.step(recall, precision, where='post')\n","    plt.fill_between(recall, precision, step='post', alpha=0.2)\n","    plt.plot(recall[best_idx], precision[best_idx], 'ro', markersize=8)\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title(f'Precision-Recall Curve\\n{model_name} (mAP: {avg_precision:.4f})')\n","    plt.grid(True)\n","\n","    # Score distributions\n","    plt.subplot(122)\n","    plt.hist(good_scores, bins=50, alpha=0.5, label='Good', density=True)\n","    plt.hist(bad_scores, bins=50, alpha=0.5, label='Defective', density=True)\n","    plt.axvline(optimal_threshold, color='r', linestyle='--', label=f'Threshold: {optimal_threshold:.2f}')\n","    plt.xlabel('Anomaly Score')\n","    plt.ylabel('Density')\n","    plt.title('Score Distributions')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Print metrics\n","    print(f\"\\n{'='*50}\")\n","    print(f\"Model: {model_name}\")\n","    print(f\"{'='*50}\")\n","    print(f\"mAP: {avg_precision:.4f}\")\n","    print(f\"AUROC: {auroc:.4f}\")\n","    print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n","    print(\"\\nClassification Report:\")\n","    print(report)\n","\n","    return avg_precision\n","\n","# Evaluate model\n","model_name = \"MultiScale-OCAD\"\n","final_map = evaluate_model(\n","    best_ocsvm,\n","    test_good_features,\n","    test_bad_features,\n","    model_name\n",")\n","\n","# Save model\n","import joblib\n","model_save_path = \"enhanced_anomaly_detector.pkl\"\n","joblib.dump(best_ocsvm, model_save_path)\n","print(f\"Model saved to {model_save_path}\")\n","\n","# Feature extractor release\n","feature_extractor.release()"],"metadata":{"id":"23C4tJN6SNg7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}